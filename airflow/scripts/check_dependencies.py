#!/usr/bin/env python3
"""
Airflow DAG ä¾è³´æª¢æŸ¥è…³æœ¬
æª¢æŸ¥æ‰€æœ‰ DAG æ–‡ä»¶ä¸­ä½¿ç”¨çš„å¤–éƒ¨ä¾è³´æ˜¯å¦åœ¨ requirements.txt ä¸­è²æ˜
"""
import os
import re
import sys
from pathlib import Path
from typing import Set, Dict, List


def extract_imports_from_file(file_path: Path) -> Set[str]:
    """å¾ Python æ–‡ä»¶ä¸­æå–å°å…¥çš„æ¨¡çµ„"""
    imports = set()

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # åŒ¹é… import èªå¥
        import_patterns = [
            r'^import\s+([a-zA-Z_][a-zA-Z0-9_]*)',  # import module
            r'^from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import',  # from module import ...
        ]

        for line in content.split('\n'):
            line = line.strip()
            if line.startswith('#') or not line:
                continue

            for pattern in import_patterns:
                match = re.match(pattern, line)
                if match:
                    module_name = match.group(1)
                    # æ’é™¤æ¨™æº–åº«å’Œç›¸å°å°å…¥
                    if not is_standard_library(module_name) and not is_relative_import(module_name):
                        imports.add(module_name)

    except Exception as e:
        print(f"Warning: Could not read {file_path}: {e}")

    return imports


def is_standard_library(module_name: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦ç‚º Python æ¨™æº–åº«æ¨¡çµ„"""
    standard_libs = {
        'os', 'sys', 'datetime', 'time', 'json', 'uuid', 'logging', 're',
        'pathlib', 'typing', 'collections', 'functools', 'itertools',
        'subprocess', 'urllib', 'http', 'email', 'xml', 'html', 'csv',
        'sqlite3', 'pickle', 'hashlib', 'base64', 'shutil', 'tempfile',
        'glob', 'fnmatch', 'math', 'random', 'statistics', 'decimal',
        'fractions', 'operator', 'copy', 'pprint', 'reprlib', 'enum',
        'contextlib', 'weakref', 'gc', 'inspect', 'dis', 'traceback'
    }
    return module_name in standard_libs


def is_relative_import(module_name: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦ç‚ºç›¸å°å°å…¥æˆ–é …ç›®å…§éƒ¨æ¨¡çµ„"""
    return module_name.startswith('.') or module_name in ['airflow', 'common']


def load_requirements(requirements_file: Path) -> Set[str]:
    """å¾ requirements.txt è¼‰å…¥å·²è²æ˜çš„ä¾è³´"""
    requirements = set()

    if not requirements_file.exists():
        return requirements

    try:
        with open(requirements_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    # æå–åŒ…åï¼ˆç§»é™¤ç‰ˆæœ¬è™Ÿå’Œå…¶ä»–ä¿®é£¾ç¬¦ï¼‰
                    package_name = re.split(r'[=<>!]', line)[0].strip()
                    if package_name:
                        requirements.add(package_name)
    except Exception as e:
        print(f"Error reading requirements file: {e}")

    return requirements


def get_package_mapping() -> Dict[str, str]:
    """
    è¿”å›å°å…¥åç¨±åˆ°åŒ…åçš„æ˜ å°„
    æœ‰äº›åŒ…çš„å°å…¥åç¨±å’Œå®‰è£åç¨±ä¸åŒ
    """
    return {
        'redis': 'redis',
        'requests': 'requests',
        'pendulum': 'pendulum',
        'pytest': 'pytest',
        'black': 'black',
        'flake8': 'flake8',
        'psycopg2': 'psycopg2-binary',
        'sqlalchemy': 'SQLAlchemy',
        'pandas': 'pandas',
        'numpy': 'numpy',
        'yfinance': 'yfinance',
        'matplotlib': 'matplotlib',
        'seaborn': 'seaborn',
        'sklearn': 'scikit-learn',
        'cv2': 'opencv-python',
        'PIL': 'Pillow',
        'yaml': 'PyYAML',
    }


def check_airflow_dependencies(airflow_dir: Path) -> Dict[str, any]:
    """æª¢æŸ¥ Airflow DAG ä¾è³´"""
    print("ğŸ” æª¢æŸ¥ Airflow DAG ä¾è³´...")

    # æŸ¥æ‰¾æ‰€æœ‰ Python æ–‡ä»¶
    python_files = list(airflow_dir.rglob("*.py"))
    print(f"æ‰¾åˆ° {len(python_files)} å€‹ Python æ–‡ä»¶")

    # æå–æ‰€æœ‰å°å…¥
    all_imports = set()
    file_imports = {}

    for py_file in python_files:
        if py_file.name.startswith('__'):
            continue

        imports = extract_imports_from_file(py_file)
        if imports:
            file_imports[str(py_file.relative_to(airflow_dir))] = imports
            all_imports.update(imports)

    # è¼‰å…¥ requirements.txt
    requirements_file = airflow_dir / "requirements.txt"
    declared_requirements = load_requirements(requirements_file)

    # æª¢æŸ¥ç¼ºå¤±çš„ä¾è³´
    package_mapping = get_package_mapping()
    missing_deps = set()

    for import_name in all_imports:
        package_name = package_mapping.get(import_name, import_name)
        if package_name not in declared_requirements:
            missing_deps.add((import_name, package_name))

    return {
        'python_files': len(python_files),
        'all_imports': all_imports,
        'file_imports': file_imports,
        'declared_requirements': declared_requirements,
        'missing_dependencies': missing_deps,
        'requirements_file_exists': requirements_file.exists()
    }


def generate_dependency_report(results: Dict[str, any]) -> None:
    """ç”Ÿæˆä¾è³´å ±å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š Airflow DAG ä¾è³´åˆ†æå ±å‘Š")
    print("="*60)

    print(f"\nğŸ“ æƒæçš„ Python æ–‡ä»¶æ•¸é‡: {results['python_files']}")
    print(f"ğŸ“¦ ç™¼ç¾çš„å¤–éƒ¨å°å…¥æ•¸é‡: {len(results['all_imports'])}")
    print(f"ğŸ“‹ requirements.txt ä¸­çš„ä¾è³´æ•¸é‡: {len(results['declared_requirements'])}")

    if not results['requirements_file_exists']:
        print("\nâŒ requirements.txt æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return

    print("\nğŸ“¦ æ‰€æœ‰å¤–éƒ¨å°å…¥:")
    for imp in sorted(results['all_imports']):
        print(f"  - {imp}")

    print("\nğŸ“‹ å·²è²æ˜çš„ä¾è³´:")
    for dep in sorted(results['declared_requirements']):
        print(f"  - {dep}")

    if results['missing_dependencies']:
        print(f"\nâŒ ç¼ºå¤±çš„ä¾è³´ ({len(results['missing_dependencies'])} å€‹):")
        for import_name, package_name in sorted(results['missing_dependencies']):
            print(f"  - {import_name} (éœ€è¦å®‰è£: {package_name})")

        print("\nğŸ”§ å»ºè­°åœ¨ requirements.txt ä¸­æ·»åŠ :")
        for import_name, package_name in sorted(results['missing_dependencies']):
            print(f"  {package_name}")
    else:
        print("\nâœ… æ‰€æœ‰ä¾è³´éƒ½å·²æ­£ç¢ºè²æ˜ï¼")

    print("\nğŸ“‚ å„æ–‡ä»¶çš„å°å…¥è©³æƒ…:")
    for file_path, imports in results['file_imports'].items():
        if imports:
            print(f"\n  ğŸ“„ {file_path}:")
            for imp in sorted(imports):
                status = "âŒ" if any(imp == missing[0] for missing in results['missing_dependencies']) else "âœ…"
                print(f"    {status} {imp}")


def suggest_fixes(results: Dict[str, any]) -> None:
    """å»ºè­°ä¿®å¾©æ–¹æ¡ˆ"""
    if not results['missing_dependencies']:
        return

    print("\n" + "="*60)
    print("ğŸ”§ ä¿®å¾©å»ºè­°")
    print("="*60)

    requirements_additions = []
    for import_name, package_name in sorted(results['missing_dependencies']):
        # æŸ¥æ‰¾å¸¸ç”¨ç‰ˆæœ¬
        version_suggestions = {
            'redis': '5.0.1',
            'requests': '2.31.0',
            'pendulum': '2.1.2',
            'pytest': '7.4.0',
            'psycopg2-binary': '2.9.7',
            'SQLAlchemy': '2.0.23',
        }

        version = version_suggestions.get(package_name, 'latest')
        if version == 'latest':
            requirements_additions.append(package_name)
        else:
            requirements_additions.append(f"{package_name}=={version}")

    print("1. æ›´æ–° airflow/requirements.txtï¼Œæ·»åŠ ä»¥ä¸‹ä¾è³´:")
    for req in requirements_additions:
        print(f"   {req}")

    print("\n2. é‡æ–°æ§‹å»º Docker æ˜ åƒ:")
    print("   docker-compose build airflow")

    print("\n3. é‡å•Ÿ Airflow æœå‹™:")
    print("   docker-compose restart airflow")


def main():
    """ä¸»å‡½æ•¸"""
    # ç¢ºå®š Airflow ç›®éŒ„
    script_dir = Path(__file__).parent
    airflow_dir = script_dir.parent

    if not airflow_dir.exists():
        print(f"âŒ Airflow ç›®éŒ„ä¸å­˜åœ¨: {airflow_dir}")
        sys.exit(1)

    print(f"ğŸ—ï¸  æª¢æŸ¥ Airflow ç›®éŒ„: {airflow_dir}")

    # åŸ·è¡Œä¾è³´æª¢æŸ¥
    try:
        results = check_airflow_dependencies(airflow_dir)
        generate_dependency_report(results)
        suggest_fixes(results)

        # æ ¹æ“šçµæœè¨­ç½®é€€å‡ºç¢¼
        if results['missing_dependencies']:
            print(f"\nâš ï¸  ç™¼ç¾ {len(results['missing_dependencies'])} å€‹ç¼ºå¤±çš„ä¾è³´")
            sys.exit(1)
        else:
            print("\nğŸ‰ æ‰€æœ‰ä¾è³´æª¢æŸ¥é€šéï¼")
            sys.exit(0)

    except Exception as e:
        print(f"âŒ æª¢æŸ¥éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()