#!/usr/bin/env python3
"""
æŠ€è¡“æŒ‡æ¨™å­˜å„²å’Œå¿«å–åŠŸèƒ½æ¸¬è©¦
"""
import asyncio
import sys
from datetime import date, timedelta

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append('/app')

from core.database import get_db
from core.redis import redis_client
from services.infrastructure.storage import indicator_storage_service
from services.infrastructure.cache import indicator_cache_service
from services.infrastructure.sync import indicator_sync_service
from services.analysis.technical_analysis import IndicatorType
from models.repositories.crud_stock import stock_crud
from models.repositories.crud_technical_indicator import technical_indicator_crud


async def test_indicator_storage():
    """æ¸¬è©¦æŒ‡æ¨™å­˜å„²åŠŸèƒ½"""
    print("=== æ¸¬è©¦æŒ‡æ¨™å­˜å„²åŠŸèƒ½ ===")
    
    try:
        await redis_client.connect()
        
        async with get_db() as db_session:
            # ç²å–æ¸¬è©¦è‚¡ç¥¨
            test_stocks = await stock_crud.get_multi(db_session, limit=3)
            if not test_stocks:
                print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦è‚¡ç¥¨")
                return False
            
            test_stock = test_stocks[0]
            print(f"ä½¿ç”¨æ¸¬è©¦è‚¡ç¥¨: {test_stock.symbol} (ID: {test_stock.id})")
            
            # æ¸¬è©¦è¨ˆç®—å’Œå­˜å„²æŒ‡æ¨™
            print("\n1. æ¸¬è©¦è¨ˆç®—å’Œå­˜å„²æŒ‡æ¨™...")
            storage_result = await indicator_storage_service.calculate_and_store_indicators(
                db_session,
                stock_id=test_stock.id,
                indicators=[IndicatorType.RSI, IndicatorType.SMA_20, IndicatorType.MACD],
                days=50,
                enable_cache=True,
                force_recalculate=True
            )
            
            if storage_result.success:
                print(f"âœ“ æˆåŠŸå­˜å„² {storage_result.indicators_stored} å€‹æŒ‡æ¨™")
                print(f"âœ“ æˆåŠŸå¿«å– {storage_result.indicators_cached} å€‹æŒ‡æ¨™")
                print(f"âœ“ åŸ·è¡Œæ™‚é–“: {storage_result.execution_time_seconds:.2f} ç§’")
            else:
                print(f"âœ— å­˜å„²å¤±æ•—: {storage_result.errors}")
                return False
            
            # æ¸¬è©¦å¾è³‡æ–™åº«æŸ¥è©¢æŒ‡æ¨™
            print("\n2. æ¸¬è©¦å¾è³‡æ–™åº«æŸ¥è©¢æŒ‡æ¨™...")
            end_date = date.today()
            start_date = end_date - timedelta(days=7)
            
            indicators = await technical_indicator_crud.get_stock_indicators_by_date_range(
                db_session,
                stock_id=test_stock.id,
                start_date=start_date,
                end_date=end_date,
                indicator_types=['RSI', 'SMA_20', 'MACD']
            )
            
            print(f"âœ“ æŸ¥è©¢åˆ° {len(indicators)} å€‹æŒ‡æ¨™è¨˜éŒ„")
            
            # æŒ‰é¡å‹åˆ†çµ„é¡¯ç¤º
            indicator_groups = {}
            for indicator in indicators:
                if indicator.indicator_type not in indicator_groups:
                    indicator_groups[indicator.indicator_type] = []
                indicator_groups[indicator.indicator_type].append(indicator)
            
            for indicator_type, type_indicators in indicator_groups.items():
                latest = max(type_indicators, key=lambda x: x.date)
                print(f"  {indicator_type}: {len(type_indicators)} å€‹è¨˜éŒ„, æœ€æ–°å€¼: {latest.value} ({latest.date})")
            
            return True
            
    except Exception as e:
        print(f"âœ— æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False
    
    finally:
        await redis_client.disconnect()


async def test_indicator_cache():
    """æ¸¬è©¦æŒ‡æ¨™å¿«å–åŠŸèƒ½"""
    print("\n=== æ¸¬è©¦æŒ‡æ¨™å¿«å–åŠŸèƒ½ ===")
    
    try:
        await redis_client.connect()
        
        async with get_db() as db_session:
            # ç²å–æ¸¬è©¦è‚¡ç¥¨
            test_stocks = await stock_crud.get_multi(db_session, limit=2)
            if not test_stocks:
                print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦è‚¡ç¥¨")
                return False
            
            test_stock = test_stocks[0]
            print(f"ä½¿ç”¨æ¸¬è©¦è‚¡ç¥¨: {test_stock.symbol} (ID: {test_stock.id})")
            
            # æ¸¬è©¦å¿«å–é ç†±
            print("\n1. æ¸¬è©¦å¿«å–é ç†±...")
            warm_up_result = await indicator_cache_service.warm_up_cache(
                db_session,
                stock_ids=[test_stock.id],
                indicator_types=['RSI', 'SMA_20', 'MACD'],
                days=30
            )
            
            if warm_up_result['successful_caches'] > 0:
                print(f"âœ“ æˆåŠŸé ç†± {warm_up_result['successful_caches']} æ”¯è‚¡ç¥¨çš„å¿«å–")
                print(f"âœ“ å¿«å– {warm_up_result['total_indicators_cached']} å€‹æŒ‡æ¨™")
            else:
                print(f"âœ— é ç†±å¤±æ•—: {warm_up_result['errors']}")
            
            # æ¸¬è©¦å¾å¿«å–å–å¾—æŒ‡æ¨™
            print("\n2. æ¸¬è©¦å¾å¿«å–å–å¾—æŒ‡æ¨™...")
            cached_data = await indicator_cache_service.get_stock_indicators_from_cache(
                test_stock.id,
                indicator_types=['RSI', 'SMA_20', 'MACD'],
                days=30
            )
            
            if cached_data:
                print(f"âœ“ å¾å¿«å–å–å¾— {len(cached_data)} ç¨®æŒ‡æ¨™é¡å‹")
                for indicator_type, data_points in cached_data.items():
                    print(f"  {indicator_type}: {len(data_points)} å€‹æ•¸æ“šé»")
            else:
                print("âœ— å¿«å–ä¸­æ²’æœ‰æ•¸æ“š")
            
            # æ¸¬è©¦å¿«å–å‘½ä¸­ç‡
            print("\n3. æ¸¬è©¦å¿«å–å‘½ä¸­ç‡...")
            
            # ç¬¬ä¸€æ¬¡æŸ¥è©¢ï¼ˆå¯èƒ½å‘½ä¸­å¿«å–ï¼‰
            start_time = asyncio.get_event_loop().time()
            data1 = await indicator_storage_service.get_indicators_with_cache(
                db_session,
                stock_id=test_stock.id,
                indicator_types=['RSI', 'SMA_20'],
                days=30,
                force_refresh=False
            )
            cache_time = asyncio.get_event_loop().time() - start_time
            
            # ç¬¬äºŒæ¬¡æŸ¥è©¢ï¼ˆå¼·åˆ¶å¾è³‡æ–™åº«ï¼‰
            start_time = asyncio.get_event_loop().time()
            data2 = await indicator_storage_service.get_indicators_with_cache(
                db_session,
                stock_id=test_stock.id,
                indicator_types=['RSI', 'SMA_20'],
                days=30,
                force_refresh=True
            )
            db_time = asyncio.get_event_loop().time() - start_time
            
            print(f"âœ“ å¿«å–æŸ¥è©¢æ™‚é–“: {cache_time:.4f} ç§’")
            print(f"âœ“ è³‡æ–™åº«æŸ¥è©¢æ™‚é–“: {db_time:.4f} ç§’")
            
            if cache_time < db_time:
                print(f"âœ“ å¿«å–æ•ˆèƒ½æå‡: {(db_time/cache_time):.2f}x")
            
            # æ¸¬è©¦å¿«å–çµ±è¨ˆ
            print("\n4. æ¸¬è©¦å¿«å–çµ±è¨ˆ...")
            cache_stats = await indicator_cache_service.get_cache_statistics()
            print(f"âœ“ å¿«å–å‘½ä¸­æ¬¡æ•¸: {cache_stats.hit_count}")
            print(f"âœ“ å¿«å–æœªå‘½ä¸­æ¬¡æ•¸: {cache_stats.miss_count}")
            print(f"âœ“ å¿«å–å‘½ä¸­ç‡: {cache_stats.hit_rate:.2%}")
            
            return True
            
    except Exception as e:
        print(f"âœ— æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False
    
    finally:
        await redis_client.disconnect()


async def test_indicator_sync():
    """æ¸¬è©¦æŒ‡æ¨™åŒæ­¥åŠŸèƒ½"""
    print("\n=== æ¸¬è©¦æŒ‡æ¨™åŒæ­¥åŠŸèƒ½ ===")
    
    try:
        await redis_client.connect()
        
        async with get_db() as db_session:
            # ç²å–æ¸¬è©¦è‚¡ç¥¨
            test_stocks = await stock_crud.get_multi(db_session, limit=3)
            if not test_stocks:
                print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦è‚¡ç¥¨")
                return False
            
            test_stock_ids = [stock.id for stock in test_stocks[:2]]
            print(f"ä½¿ç”¨æ¸¬è©¦è‚¡ç¥¨: {[stock.symbol for stock in test_stocks[:2]]}")
            
            # æ¸¬è©¦å»ºç«‹åŒæ­¥æ’ç¨‹
            print("\n1. æ¸¬è©¦å»ºç«‹åŒæ­¥æ’ç¨‹...")
            schedule_result = await indicator_sync_service.create_sync_schedule(
                schedule_name="test_schedule",
                stock_ids=test_stock_ids,
                indicator_types=['RSI', 'SMA_20', 'MACD'],
                sync_frequency='manual'
            )
            
            if schedule_result['success']:
                print(f"âœ“ æˆåŠŸå»ºç«‹åŒæ­¥æ’ç¨‹")
                print(f"  è‚¡ç¥¨æ•¸é‡: {schedule_result['stock_count']}")
                print(f"  æŒ‡æ¨™æ•¸é‡: {schedule_result['indicator_count']}")
            else:
                print(f"âœ— å»ºç«‹æ’ç¨‹å¤±æ•—: {schedule_result['error']}")
                return False
            
            # æ¸¬è©¦åŸ·è¡ŒåŒæ­¥æ’ç¨‹
            print("\n2. æ¸¬è©¦åŸ·è¡ŒåŒæ­¥æ’ç¨‹...")
            sync_result = await indicator_sync_service.execute_sync_schedule(
                "test_schedule",
                force_sync=True
            )
            
            if sync_result['success']:
                print(f"âœ“ åŒæ­¥æ’ç¨‹åŸ·è¡ŒæˆåŠŸ")
                print(f"  è™•ç†è‚¡ç¥¨: {sync_result['stocks_processed']}")
                print(f"  æ›´æ–°æŒ‡æ¨™: {sync_result['indicators_updated']}")
                print(f"  åˆ·æ–°å¿«å–: {sync_result['cache_refreshed']}")
            else:
                print(f"âœ— åŒæ­¥æ’ç¨‹åŸ·è¡Œå¤±æ•—: {sync_result['error']}")
            
            # æ¸¬è©¦å–®æ”¯è‚¡ç¥¨åŒæ­¥
            print("\n3. æ¸¬è©¦å–®æ”¯è‚¡ç¥¨åŒæ­¥...")
            single_sync_result = await indicator_sync_service.sync_single_stock(
                stock_id=test_stock_ids[0],
                indicator_types=['RSI', 'EMA_12'],
                force_recalculate=True
            )
            
            if single_sync_result['success']:
                print(f"âœ“ å–®æ”¯è‚¡ç¥¨åŒæ­¥æˆåŠŸ")
                print(f"  è‚¡ç¥¨ä»£è™Ÿ: {single_sync_result['stock_symbol']}")
                print(f"  å­˜å„²æŒ‡æ¨™: {single_sync_result['indicators_stored']}")
                print(f"  å¿«å–æŒ‡æ¨™: {single_sync_result['indicators_cached']}")
            else:
                print(f"âœ— å–®æ”¯è‚¡ç¥¨åŒæ­¥å¤±æ•—: {single_sync_result['error']}")
            
            # æ¸¬è©¦åŒæ­¥ç‹€æ…‹
            print("\n4. æ¸¬è©¦åŒæ­¥ç‹€æ…‹...")
            sync_status = await indicator_sync_service.get_sync_status()
            print(f"âœ“ åŒæ­¥é‹è¡Œä¸­: {sync_status['is_running']}")
            print(f"âœ“ æ´»èºæ’ç¨‹æ•¸: {sync_status['active_schedules']}")
            
            # æ¸¬è©¦æ’ç¨‹åˆ—è¡¨
            print("\n5. æ¸¬è©¦æ’ç¨‹åˆ—è¡¨...")
            schedules = await indicator_sync_service.get_sync_schedules()
            print(f"âœ“ æ‰¾åˆ° {len(schedules)} å€‹æ’ç¨‹")
            for name, info in schedules.items():
                print(f"  {name}: {info['stock_count']} æ”¯è‚¡ç¥¨, ç‹€æ…‹: {'å•Ÿç”¨' if info['enabled'] else 'åœç”¨'}")
            
            # æ¸…ç†æ¸¬è©¦æ’ç¨‹
            await indicator_sync_service.delete_schedule("test_schedule")
            print("âœ“ æ¸…ç†æ¸¬è©¦æ’ç¨‹")
            
            return True
            
    except Exception as e:
        print(f"âœ— æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False
    
    finally:
        await redis_client.disconnect()


async def test_data_integrity():
    """æ¸¬è©¦æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥"""
    print("\n=== æ¸¬è©¦æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥ ===")
    
    try:
        await redis_client.connect()
        
        async with get_db() as db_session:
            # ç²å–æ¸¬è©¦è‚¡ç¥¨
            test_stocks = await stock_crud.get_multi(db_session, limit=1)
            if not test_stocks:
                print("éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦è‚¡ç¥¨")
                return False
            
            test_stock = test_stocks[0]
            print(f"æª¢æŸ¥è‚¡ç¥¨: {test_stock.symbol} (ID: {test_stock.id})")
            
            # æ¸¬è©¦æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
            integrity_result = await indicator_storage_service.validate_data_integrity(
                db_session,
                stock_id=test_stock.id,
                days=30
            )
            
            if integrity_result['success']:
                report = integrity_result['integrity_report']
                print(f"âœ“ æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥å®Œæˆ")
                print(f"  æ•´é«”å¥åº·ç‹€æ…‹: {report['overall_health']}")
                print(f"  æª¢æŸ¥æœŸé–“: {report['check_period']}")
                print(f"  ç™¼ç¾å•é¡Œ: {integrity_result['issues_found']} å€‹")
                
                for indicator_type, info in report['indicator_types'].items():
                    print(f"  {indicator_type}:")
                    print(f"    æ•¸æ“šå®Œæ•´åº¦: {info['actual_days']}/{info['expected_days']} å¤©")
                    print(f"    å¥åº·ç‹€æ…‹: {info['health_status']}")
                    
                    if info['issues']:
                        for issue in info['issues']:
                            print(f"    å•é¡Œ: {issue}")
            else:
                print(f"âœ— æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: {integrity_result['error']}")
                return False
            
            # æ¸¬è©¦å­˜å„²çµ±è¨ˆ
            print("\næ¸¬è©¦å­˜å„²çµ±è¨ˆ...")
            stats = await indicator_storage_service.get_storage_statistics(db_session)
            
            print(f"âœ“ è³‡æ–™åº«çµ±è¨ˆ:")
            db_stats = stats['database']
            print(f"  ç¸½æŒ‡æ¨™æ•¸: {db_stats.get('total_indicators', 0):,}")
            print(f"  ç¸½è‚¡ç¥¨æ•¸: {db_stats.get('total_stocks', 0)}")
            print(f"  æŒ‡æ¨™é¡å‹æ•¸: {db_stats.get('total_indicator_types', 0)}")
            
            print(f"âœ“ å¿«å–çµ±è¨ˆ:")
            cache_stats = stats['cache']
            print(f"  å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0):.2%}")
            print(f"  ç¸½éµæ•¸: {cache_stats.get('total_keys', 0):,}")
            
            return True
            
    except Exception as e:
        print(f"âœ— æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False
    
    finally:
        await redis_client.disconnect()


async def run_all_tests():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("é–‹å§‹åŸ·è¡ŒæŠ€è¡“æŒ‡æ¨™å­˜å„²å’Œå¿«å–åŠŸèƒ½æ¸¬è©¦...\n")
    
    tests = [
        ("æŒ‡æ¨™å­˜å„²åŠŸèƒ½", test_indicator_storage),
        ("æŒ‡æ¨™å¿«å–åŠŸèƒ½", test_indicator_cache),
        ("æŒ‡æ¨™åŒæ­¥åŠŸèƒ½", test_indicator_sync),
        ("æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥", test_data_integrity)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"åŸ·è¡Œæ¸¬è©¦: {test_name}")
        print('='*60)
        
        try:
            result = await test_func()
            if result:
                print(f"\nâœ“ {test_name} æ¸¬è©¦é€šé")
                passed += 1
            else:
                print(f"\nâœ— {test_name} æ¸¬è©¦å¤±æ•—")
        except Exception as e:
            print(f"\nâœ— {test_name} æ¸¬è©¦ç•°å¸¸: {str(e)}")
    
    print(f"\n{'='*60}")
    print(f"æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    print('='*60)
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦éƒ½é€šéäº†ï¼")
        return True
    else:
        print("âŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
        return False


if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)